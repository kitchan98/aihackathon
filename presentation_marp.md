---
marp: true
theme: default

style: |
    .columns {
        display: grid;
        grid-template-columns: repeat(2, minmax(0, 1fr));
        gap: 1rem;
    }
---

# Multi-Label Image Classification

- Multi-label image classification predicts all applicable labels for images.
- More challenging than standard multi-class classification due to multiple labels.
- Data annotation in multi-label setting requires labeling each category present/absent.
- Laborious process compared to single-label classification for image categorization.

----

# Multi-Label Image Classification

<div class="columns">
<div>

![width:500px](output_images/002305_4253978046.png)

</div>

<div>

- Multi-label image classification predicts all applicable labels for images.
- More challenging than standard multi-class classification due to multiple labels.
- Data annotation in multi-label setting requires labeling each category present/absent.
- Laborious process compared to single-label classification for image categorization.
</div>
</div>

----

# Single Positive Multi-Label Learning

- SPML: Cost-effective solution for multi-label image classification.
- Models trained on single positive label per image in SPML.
- Main challenge in SPML: Effectively dealing with missing labels.
- Previous approaches like 'Assume Negative' and 'Entropy Maximization' limited.

----

# Single Positive Multi-Label Learning

<div class="columns">
<div>

![width:500px](output_images/002315_4253978046.png)

</div>

<div>

- SPML: Cost-effective solution for multi-label image classification.
- Models trained on single positive label per image in SPML.
- Main challenge in SPML: Effectively dealing with missing labels.
- Previous approaches like 'Assume Negative' and 'Entropy Maximization' limited.
</div>
</div>

----

# Pseudo Labels for SPML

- Adapt 'Pseudo Labels' from image classification to SPML setting.
- Train 'teacher' network on single positive labels for ground-truth.
- Train 'student' network on fully-labeled images using teacher predictions.
- Recover supervision from partially labeled data with innovative approach.

----

# Pseudo Labels for SPML

<div class="columns">
<div>

![width:500px](output_images/002325_4253978046.png)

</div>

<div>

- Adapt 'Pseudo Labels' from image classification to SPML setting.
- Train 'teacher' network on single positive labels for ground-truth.
- Train 'student' network on fully-labeled images using teacher predictions.
- Recover supervision from partially labeled data with innovative approach.
</div>
</div>

----

# Pseudo Multi-Labels Algorithm

- Pseudo Multi-Labels: Generated by thresholding 'TeacherNet' predicted probabilities.
- TeacherNet trained on single positive dataset to generate pseudo labels.
- StudentNet trained on Pseudo Multi-Labels as fully-labeled data.
- Threshold parameter controls strictness of 'TeacherNet' predictions for labels.

----

# Pseudo Multi-Labels Algorithm

<div class="columns">
<div>

![width:500px](output_images/002336_4253978046.png)

</div>

<div>

- Pseudo Multi-Labels: Generated by thresholding 'TeacherNet' predicted probabilities.
- TeacherNet trained on single positive dataset to generate pseudo labels.
- StudentNet trained on Pseudo Multi-Labels as fully-labeled data.
- Threshold parameter controls strictness of 'TeacherNet' predictions for labels.
</div>
</div>

----

# Experimental Setup

- Single positive label per image in COCO dataset for clarity.
- Validation and test sets preserved; Pseudo Multi-Labels algorithm applied.
- Varying threshold values used to manage positive labels per image.
- Ensured uniformity and control in labeling process for dataset.

----

# Experimental Setup

<div class="columns">
<div>

![width:500px](/var/folders/nq/5cq8wml153vdwrknr26h6p980000gn/T/tmpwfvqa8x8/arXiv-2306.01034v1/plots/pml_iclr_num_labels.png)

</div>

<div>

- Single positive label per image in COCO dataset for clarity.
- Validation and test sets preserved; Pseudo Multi-Labels algorithm applied.
- Varying threshold values used to manage positive labels per image.
- Ensured uniformity and control in labeling process for dataset.
</div>
</div>

----

# Results

- Outperforms 'Assume Negative' baseline, falls short of 'Entropy Maximization'
- Hard cutoff on 'TeacherNet' may introduce noisy labels
- Performance comparison with 'Assume Negative' and 'Entropy Maximization'
- Limitation: Potential noisy labels due to 'Pseudo Multi-Labels' generation

----

# Results

<div class="columns">
<div>

![width:500px](/var/folders/nq/5cq8wml153vdwrknr26h6p980000gn/T/tmpwfvqa8x8/arXiv-2306.01034v1/plots/pml_iclr_main.png)

</div>

<div>

- Outperforms 'Assume Negative' baseline, falls short of 'Entropy Maximization'
- Hard cutoff on 'TeacherNet' may introduce noisy labels
- Performance comparison with 'Assume Negative' and 'Entropy Maximization'
- Limitation: Potential noisy labels due to 'Pseudo Multi-Labels' generation
</div>
</div>

----

# Conclusion and Future Work

- Pseudo Multi-Labels outperform 'Assume Negative' but not 'Entropy Maximization'.
- Hard cutoff on 'TeacherNet' may introduce noisy labels, a limitation.
- Future work: Explore advanced techniques for generating pseudo labels.
- Consider combining our approach with 'Entropy Maximization' for improvement.

----

# Conclusion and Future Work

<div class="columns">
<div>

![width:500px](output_images/002347_4253978046.png)

</div>

<div>

- Pseudo Multi-Labels outperform 'Assume Negative' but not 'Entropy Maximization'.
- Hard cutoff on 'TeacherNet' may introduce noisy labels, a limitation.
- Future work: Explore advanced techniques for generating pseudo labels.
- Consider combining our approach with 'Entropy Maximization' for improvement.
</div>
</div>

----

Thank You!
